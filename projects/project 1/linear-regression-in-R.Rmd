---
title: "Linear regression in R"
author: "Erin Shellman"
date: "April 13 & 20, 2015"
output: html_document
---

## Linear regression 

http://topepo.github.io/caret/Linear_Regression.html

### Data preparation

We're working with the Capital Bikeshare again this week, so start by reading in
*usage*, *weather*, *stations*.
```{r, eval = FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)

usage = read.delim('usage_2012.tsv',
                   sep = '\t',
                   header = TRUE)

weather = read.delim('daily_weather.tsv',
                   sep = '\t',
                   header = TRUE)

stations = read.delim('stations.tsv',
                   sep = '\t',
                   header = TRUE)
```

```{r, echo = FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)

setwd('~/projects/BI-TECH-CP303/projects/project 1')
usage = read.delim('./data/usage_2012.tsv',
                   sep = '\t',
                   header = TRUE)

stations = read.delim('./data/stations.tsv',
                   sep = '\t',
                   header = TRUE)

weather = read.delim('./data/daily_weather.tsv',
                   sep = '\t',
                   header = TRUE)
```

### Merging data

We have three related datasets to work with, but we can't really get started 
until we figure out how to combine them. Let's start with *usage* and *weather*.
The *usage* dataframe is at the resolution of the hour, while the *weather* data
are at the resolution of a day, so we know we're going to have to either 
duplicate or compress data to merge. I vote compress, let's summarize! 
```{r}
custs_per_day = usage %>% 
  group_by(time_start = as.Date(time_start), station_start) %>% 
  summarize(no_rentals = n())

head(custs_per_day)
```

Perfection, now we can merge!  What's the key?
```{r}
# make sure we have consistent date formats
custs_per_day$time_start = ymd(custs_per_day$time_start)
weather$date = ymd(weather$date)

weather_rentals = merge(custs_per_day, weather, 
                        by.x = 'time_start', by.y = 'date')

# I like to check dimensions after to make sure they are what I'd expect
dim(custs_per_day)
dim(weather)
dim(weather_rentals)

head(weather_rentals)
```

Great, now we want to merge on the last dataset, *stations*. What is the key to 
link *weather_rentals* with *stations*?
```{r}
final_data = merge(weather_rentals, stations, 
                   by.x = 'station_start', by.y = 'station')
dim(final_data)
dim(weather_rentals)

head(final_data)

# probably want to save this now!
write.table(final_data, 'bikeshare_modeling_data.tsv', row.names = FALSE, sep = '\t')

# rename to something more convenient and remove from memory
data = final_data
rm(final_data)
```

### The `lm()` function

## Test and Train data

### The *caret* package

The *caret* package in R contains helper functions that provide a unified 
framework for data cleaning/splitting, and model training and comparison.  

```{r}
install.packages('caret', dependencies = TRUE)
library(caret)
```

Setting a seed in R insures that you get identical results each time you run
your code. Since resampling methods are inherently probabilistic, every time we 
rerun them we'll get slightly different answers. Setting the seed to the same 
number insures that we get identical randomness each time the code is run, and
that's helpful for debugging.

### Splitting data into test and train sets

In data mining we're interested in creating models for prediction, and we'll 
assess the quality of our models by quantifying their prediction accuracy. To 
measure prediction quality, we hold out a portion of our data called the *test*
set. The *training* data is used to build the model.
```{r}
set.seed(1234) # set a seed

# select the training observations
in_train = createDataPartition(y = data$no_rentals,
                                   p = 0.75, # 75% in train, 25% in test.
                                   list = FALSE)
head(in_train) # row indices of observations in the training set

training_set = data[in_train, ]
testing_set = data[-in_train, ]

dim(training_set)
dim(testing_set)
```

```{r}

model_fit = train(no_rentals ~., data = select(training_set, -station_start, -time_start, -season_code, -weather_code), method = 'lm') 

model_fit = lm(no_rentals ~ factor(is_holiday) + temp + grave_yard, data = data)
model_fit = lm(no_rentals ~ factor(is_holiday) + temp + bar, data = data)
summary(model_fit)

```

## Exploratory

featurePlot()

Plotting notes:

Makes your plots only on the training set and don't use the test set for 
exploration.

You're looking for imbalances in the outcome/predictors
outliers, groups of points not explained by a predictor, skewness.


#### Preprocessing

###### Skew

During your exploration, you might encounter skewness.  One tell-tale sign is a 
mean and median being very different.  Or a distribution with a large standard
deviation relative its mean.  One way to handle situations like this is to 
standardize your data.  Can use `scale`.  One thing to note is that if you
standardize your training set, you must identically standardize your testing set.
In the case of center scaling, the mean you subtract off and the standard 
deviation you divide by are the mean and standard deviation computed with the
training set, **not** the test set.  That means your average value might not be
distributed exactly $ N(0, 1) $.

preprocessor = preProcess(taining[ , cols], method = c('center', 'scale'))
test_set_processed = predict(preprocessor, testing[ , cols])

###### Missingness

preProcess(taining, method = 'knnImpute')

## Fitting / Training

A workhorse function in the *caret* package in the `train` function.  This
function can be used to evaluate performance parameters, choose optimal models 
based on the values of those parameters, and estimate model performance.

```{r}
#model_fit = train(type ~., data = training_set, method = 'glm')
#model_fit = train(Fertility ~., data = swiss, method = 'lm') 
#summary(model_fit)
```

Explain the output.

## Prediction

```{r}
#predictions = predict(model_fit, newdata = testing_set)

```

## Diagnostics

The `confusionMatrix` function prints a lot of diagnostic measures that you
might want to evaluate when developing your models.

```{r}
#confusionMatrix(predictions, testing_set$type)

```

## Feature Selection

Feature extraction at its most basic level is done by the context of the problem
being solved. If you're trying to estimate the time of day when load on a 
server will near capacity, the features you include in your data will naturally 
be related.  Time, number of requests per second.

Feature creation can also be done via exploratory analysis as trends and 
patterns emerge.

dummyVars()
nearZeroVar()

## Linear regression extensions

Lots of regression methods [here](http://topepo.github.io/caret/Linear_Regression.html).

Forward selection
model_fit = train(Fertility ~., data = swiss, method = 'leapForward') 
Stepwise selection
model_fit = train(Fertility ~., data = swiss, method = 'leapSeq') 
partial least squares
model_fit = train(Fertility ~., data = swiss, method = 'pls') 
penalized linear regression
model_fit = train(Fertility ~., data = swiss, method = 'penalized') 
lasso
model_fit = train(Fertility ~., data = swiss, method = 'lass') 

## Project tips

Provide them with some guidance, suggestions and code snippets for the project.




